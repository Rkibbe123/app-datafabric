{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50f0523-5362-47aa-b9b4-8695465508bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Process Config Classes"
    }
   },
   "outputs": [],
   "source": [
    "%run ./ProcessConfigHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "191f4ff5-9098-4485-9c32-05862dd17eaf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Lakeflow API Classes"
    }
   },
   "outputs": [],
   "source": [
    "%run ./LakeflowAPIHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfc40c5f-f49e-4241-af13-46fea9a32d38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Unity Catalog Classes"
    }
   },
   "outputs": [],
   "source": [
    "%run ./UnityCatalogHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c74f0dcb-73ec-483c-b37d-e97800c9616f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Python Modules"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "039fd98f-eec5-4d5d-bf61-3db0ed4f8730",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CreateSqlGatewayPipeline"
    }
   },
   "outputs": [],
   "source": [
    "class CreateSqlGatewayPipeline:\n",
    "    def __init__(self, p_environment,  p_internal_product_id, p_source_server_name, p_source_database_name=None, p_internal_client_id=None, p_internal_facility_id=None):\n",
    "        self.params_dict = {\n",
    "            'p_environment': p_environment,\n",
    "            'p_internal_product_id': p_internal_product_id,\n",
    "            'p_source_server_name': p_source_server_name,\n",
    "            'p_source_database_name': p_source_database_name,\n",
    "            'p_internal_client_id': p_internal_client_id,\n",
    "            'p_internal_facility_id': p_internal_facility_id\n",
    "        }\n",
    "\n",
    "        self.process_max_workers = 10\n",
    "        self.trackeback_length = 1000\n",
    "\n",
    "    def set_process_max_workers(self, process_max_workers):\n",
    "        self.process_max_workers = process_max_workers\n",
    "\n",
    "    def get_process_max_workers(self):\n",
    "        return self.process_max_workers\n",
    "    \n",
    "    def set_traceback_length(self, traceback_length):\n",
    "        self.trackeback_length = traceback_length\n",
    "\n",
    "    def get_traceback_length(self):\n",
    "        return self.trackeback_length\n",
    "    \n",
    "    def process(self):\n",
    "\n",
    "        v_thread_errors = []        # To collect all exceptions\n",
    "        v_thread_results = []       # To collect successful results\n",
    "        v_validation_errors = []    # To collect validation errors\n",
    "        v_skipped_results = []      # To collect skipped results\n",
    "        v_config_row_array = []     # To collect valid config rows to process\n",
    "        # Initialize Return Dictionary - will display results in that order using pprint\n",
    "        v_return_dict = {'Total': 0,'Success': 0, 'SuccessResults': [], 'Skipped': 0, 'SkippedResults': [], 'ValidationFailed' : 0, 'ValidationFailures': [], 'ExecutionFailed' : 0, 'ExecutionFailures': []}\n",
    "        # Retrieve Unity Catalog from Configuration and Manage Location Root Path\n",
    "        process_config = ProcessConfigData(self.params_dict['p_environment'])\n",
    "        v_unity_catalog = process_config.get_config_attribute_value('AnalyticsUnityCatalog')\n",
    "        v_managed_location_root_path = process_config.get_config_attribute_value('AdlsAnalyticsFullpathUri')\n",
    "        # Retrieve new pipelines Configuration Data\n",
    "        df_config_data_rows = process_config.get_server_list(\n",
    "                                                                                            self.params_dict['p_internal_product_id'],\n",
    "                                                                                            self.params_dict['p_source_server_name'], \n",
    "                                                                                            self.params_dict['p_source_database_name'],\n",
    "                                                                                            self.params_dict['p_internal_client_id'],\n",
    "                                                                                            self.params_dict['p_internal_facility_id']\n",
    "                                                                                        )\n",
    "        # Raise exception if no configurations found\n",
    "        if df_config_data_rows is None or df_config_data_rows.count() == 0:\n",
    "            raise Exception(f\"Unable to find implementation configuration for {self.params_dict}\")\n",
    "        else:\n",
    "            v_return_dict['Total'] = df_config_data_rows.count()\n",
    "            #print(df_config_data_rows, \"---\\n---\", df_config_data_rows.count())\n",
    "            #df_config_data_rows.display()\n",
    "        # Loop through new Configurations - Skip if Gateway already created...\n",
    "        for row in df_config_data_rows.collect():\n",
    "            if row['GatewayPipelineId']:\n",
    "                v_return_dict['Skipped'] += 1\n",
    "                v_skipped_message = f\"Warning: SKipping - PipelineID ({row['GatewayPipelineId']}) is filled in for this implementation: Pipeline={row['GatewayPipelineName']}, Server={row['SourceServerName1']}, Database={row['SourceDatabaseName1']}\"\n",
    "                v_skipped_results.append(v_skipped_message)\n",
    "                print(v_skipped_message)\n",
    "            else:\n",
    "                # Get row as Dictionary and Validate Attributes\n",
    "                v_config_row_dict = row.asDict()\n",
    "                v_validation_message = self.validate_config_row(v_config_row_dict)\n",
    "                # If Validate Successfully, add additional Attributes to row dictionary and save in array to process\n",
    "                if v_validation_message is None:\n",
    "                    v_config_row_dict['Status'] = 'Pending'\n",
    "                    v_config_row_dict['DestinationCatalog'] = v_unity_catalog\n",
    "                    v_config_row_dict['ManagedLocationRootPath'] = v_managed_location_root_path\n",
    "                    v_config_row_dict['process_config'] = process_config\n",
    "                    v_config_row_dict['ProcessIdentifier'] = f\"Pipeline={v_config_row_dict['GatewayPipelineName']} Server={v_config_row_dict['SourceServerName1']} Database={v_config_row_dict['SourceDatabaseName1']}\"\n",
    "                    v_config_row_array.append(v_config_row_dict)\n",
    "                    print(f\"Implementation will proceed for {row['GatewayPipelineName']}, Server={row['SourceServerName1']}, Database={row['SourceDatabaseName1']}\")\n",
    "                else:\n",
    "                    # Collect Validation Failure Details and save in array to display at process end.\n",
    "                    v_return_dict['ValidationFailed'] += 1\n",
    "                    v_validation_message = f\"Implementation will NOT proceed for {row['GatewayPipelineName']}, Server={row['SourceServerName1']}, Database={row['SourceDatabaseName1']}: {v_validation_message}\"\n",
    "                    v_validation_errors.append(v_validation_message)\n",
    "                    print(v_validation_message)\n",
    "\n",
    "        if len(v_config_row_array) == 0:\n",
    "            v_return_dict['ValidationFailures'] = v_validation_errors\n",
    "            v_return_dict['SkippedResults'] = v_skipped_results\n",
    "        else:\n",
    "            # Launch New Gateways to Create based on Configuration in parallel...\n",
    "            # Collect Thread Results and Errors\n",
    "            print(f\"Processing {len(v_config_row_array)} rows.....\")\n",
    "            with ThreadPoolExecutor(max_workers=self.get_process_max_workers()) as executor:\n",
    "                futures = {executor.submit(self.process_config_row, obj): obj for obj in v_config_row_array}\n",
    "                for future in as_completed(futures):\n",
    "                    obj = futures[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        v_pipeline_id = result['pipeline_id'] if 'pipeline_id' in result else None\n",
    "                        v_thread_results.append(str(obj['ProcessIdentifier']) + ' \\nMessage=Gateway Successfully Created - ID: ' + str(v_pipeline_id))\n",
    "                        #print(f\"Thread Successes: \", v_thread_results)\n",
    "                    except Exception as e:\n",
    "                        v_thread_errors.append(str(obj['ProcessIdentifier']) + ' \\nMessage=' + str(e).replace('\\n','')[0:self.get_traceback_length()])\n",
    "                        #print(f\"Thread Errors: \", v_thread_errors)\n",
    "        # Collect Run Statistics\n",
    "        v_return_dict['Success'] = len(v_thread_results)\n",
    "        v_return_dict['SuccessResults'] = v_thread_results\n",
    "        v_return_dict['SkippedResults'] = v_skipped_results\n",
    "        v_return_dict['ValidationFailures'] = v_validation_errors\n",
    "        v_return_dict['ExecutionFailed'] = len(v_thread_errors)\n",
    "        v_return_dict['ExecutionFailures'] = v_thread_errors\n",
    "        # Display Summary\n",
    "        print(\"\\n\\nSummary:\\n\")\n",
    "        pprint.pprint(v_return_dict, indent=4, compact=True, sort_dicts=False, width=10000)\n",
    "        # Raise Exception if any errors were encountered or no Configurations to Process\n",
    "        if len(v_thread_errors) + len(v_validation_errors) > 0:\n",
    "            raise Exception(f\"{len(v_thread_errors)} Execution errors and {len(v_validation_errors)} Validation Errors were encountered during processing. See exception for details.\")\n",
    "        elif len(v_config_row_array) == 0:\n",
    "            raise Exception(f\"Unable to find valid implementation configuration(s) for {self.params_dict} - Skipped: {len(v_skipped_results)}\")\n",
    "            \n",
    "        return v_return_dict\n",
    "            \n",
    "            \n",
    "\n",
    "    def validate_config_row(self, p_config_row_dict):\n",
    "        validation_message = ''\n",
    "        if p_config_row_dict['SourceServerName1'] is None:\n",
    "            validation_message += 'SourceServerName1 is required\\n'\n",
    "        if p_config_row_dict['SourceDatabaseName1'] is None:\n",
    "            validation_message += 'SourceDatabaseName1 is required\\n'\n",
    "        if p_config_row_dict['GatewayPipelineName'] is None:\n",
    "            validation_message += 'GatewayPipelineName is required\\n'\n",
    "        if p_config_row_dict['DestinationSchema'] is None:\n",
    "            validation_message += 'DestinationSchema is required\\n'\n",
    "        if p_config_row_dict['ConfigJSON'] is None:\n",
    "            validation_message += 'ConfigJSON is required\\n'\n",
    "        else:\n",
    "            try:\n",
    "                v_json = json.loads(p_config_row_dict['ConfigJSON'])\n",
    "                if 'initial_cluster_spec' not in v_json:\n",
    "                    validation_message += 'ConfigJSON is missing \"initial_cluster_spec\"\\n'\n",
    "                if 'connection_name' not in v_json:\n",
    "                    validation_message += 'ConfigJSON is missing \"connection_name\"\\n' \n",
    "            except:\n",
    "                validation_message += 'ConfigJSON is not valid JSON\\n'\n",
    "        \n",
    "        return validation_message if validation_message != '' else None\n",
    "    \n",
    "    def build_pipeline_json_dict(self, p_config_row_dict):\n",
    "        # Pick the Large Cluster Initially\n",
    "        v_json_clusters_dict = json.loads(p_config_row_dict['ClusterJSONSpecsLarge'])\n",
    "        \n",
    "        return {\n",
    "                \"name\": p_config_row_dict['GatewayPipelineName'],\n",
    "                \"catalog\": p_config_row_dict['DestinationCatalog'],\n",
    "                \"target\": p_config_row_dict['DestinationSchema'],\n",
    "                \"clusters\": v_json_clusters_dict[\"clusters\"],\n",
    "                \"gateway_definition\":   {\n",
    "                                            \"connection_name\" : p_config_row_dict['ConnectionName'],\n",
    "                                            \"gateway_storage_catalog\": p_config_row_dict['DestinationCatalog'],\n",
    "                                            \"gateway_storage_schema\" : p_config_row_dict['DestinationSchema'],\n",
    "                                        }\n",
    "                }\n",
    "        \n",
    "    def create_destination_schema(self, p_config_row_dict):\n",
    "        v_uc_obj = UnityCatalog()\n",
    "        v_schema_managed_location = f\"{p_config_row_dict['ManagedLocationRootPath']}/{p_config_row_dict['DestinationSchema']}\"\n",
    "        return v_uc_obj.create_schema(p_config_row_dict['DestinationCatalog'], p_config_row_dict['DestinationSchema'], v_schema_managed_location)\n",
    "\n",
    "    def process_config_row(self, p_config_row_dict):\n",
    "\n",
    "        try:\n",
    "            # This function can be called outside of the main process function, so we need to make sure we have the process_config object instantiated\n",
    "            if 'process_config' not in p_config_row_dict:\n",
    "                p_config_row_dict['process_config'] = process_config = ProcessConfigData(self.params_dict['p_environment'])\n",
    "\n",
    "            v_api_json_data_dict = self.build_pipeline_json_dict(p_config_row_dict)\n",
    "            self.create_destination_schema(p_config_row_dict)\n",
    "            v_lakeflow_api = LakeflowGatewayAPI()\n",
    "            reponse_dict = v_lakeflow_api.create_gateway_pipeline(v_api_json_data_dict)\n",
    "\n",
    "            if reponse_dict['status'] == 'ok':\n",
    "                p_config_row_dict['GatewayPipelineId'] = reponse_dict['pipeline_id']\n",
    "                self.process_config_update_pipeline_id(p_config_row_dict)\n",
    "\n",
    "                # Set Permissions if defined\n",
    "                gb_vars_obj = GlobalVars(self.params_dict['p_environment'])\n",
    "                v_permissions_list = gb_vars_obj.get_pipeline_permissions_list()\n",
    "                if v_permissions_list is not None and len(v_permissions_list) > 0:\n",
    "                    v_lakeflow_api.update_pipeline_permissions(p_config_row_dict['GatewayPipelineId'], v_permissions_list)\n",
    "                \n",
    "                # Wait up to 30 minutes for Gateway to be in Running State\n",
    "                api_ext_obj = LakeflowAPIExtension()\n",
    "                api_ext_obj.wait_for_gateway_running(p_config_row_dict['GatewayPipelineId'], 30)\n",
    "            else:\n",
    "                raise Exception (f\"Error: Create Gateway Pipeline Failed for {p_config_row_dict['ProcessIdentifier']}: str({reponse_dict})\")\n",
    "            print(\"Response:\", reponse_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {p_config_row_dict['ProcessIdentifier']} {e}\")\n",
    "            raise Exception(f\"Error: {p_config_row_dict['ProcessIdentifier']} {e}\")\n",
    "        return reponse_dict\n",
    "\n",
    "    def process_config_update_pipeline_id(self, p_config_row_dict):\n",
    "        v_stored_procedure_params_dict = { \n",
    "                                          'PipelineType': 'Gateway',\n",
    "                                          'InternalProductId': p_config_row_dict['InternalProductId'],\n",
    "                                          'SourceServerName1': p_config_row_dict['SourceServerName1'],\n",
    "                                          'SourceDatabaseName1': p_config_row_dict['SourceDatabaseName1'],\n",
    "                                          'SourceConfigTable': p_config_row_dict['SourceConfigTable'],\n",
    "                                          'PipelineID': p_config_row_dict['GatewayPipelineId'],\n",
    "                                        }\n",
    "\n",
    "        p_config_row_dict['process_config'].set_pipeline_id(v_stored_procedure_params_dict)\n",
    "\n",
    "    def get_gateway_api(self):\n",
    "        return LakeflowGatewayAPI()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a60acaec-45eb-4336-b10b-8dbbc1e9ffb7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "UpdateSqlGatewayPipeline"
    }
   },
   "outputs": [],
   "source": [
    "class UpdateSqlGatewayPipeline:\n",
    "    def __init__(self, p_pipeline_id):\n",
    "        self.pipeline_id = p_pipeline_id\n",
    "        self.lakeflow_api = LakeflowGatewayAPI()\n",
    "\n",
    "    def get_pipeline_json(self):\n",
    "        return self.lakeflow_api.get_pipeline(self.pipeline_id)\n",
    "    \n",
    "    def update_pipeline_clusters(self, p_cluster_list):\n",
    "        return_dict = {'status': 'error'}\n",
    "\n",
    "        v_json_dict = self.get_pipeline_json()\n",
    "        return_dict['response'] = v_json_dict['response']\n",
    "\n",
    "        if v_json_dict['status'] == 'ok':\n",
    "            v_pipeline_spec = v_json_dict['response']['spec']\n",
    "            v_pipeline_spec['clusters'] = p_cluster_list\n",
    "            v_update_response_dict = self.lakeflow_api.update_pipeline(self.pipeline_id, v_pipeline_spec)\n",
    "            return_dict.update(v_update_response_dict)\n",
    "            if v_update_response_dict['status'] == 'ok':\n",
    "                return_dict['message'] = 'Pipeline Clusters Updated'\n",
    "            else:\n",
    "                return_dict['message'] =  'Pipeline Clusters Updated Failed'  \n",
    "        else:\n",
    "            return_dict['message'] = f'Pipeline Get Definition Failed: See Response Object'\n",
    "\n",
    "        return return_dict\n",
    "    \n",
    "    def update_pipeline_name(self, p_name):\n",
    "        return_dict = {'status': 'error'}\n",
    "\n",
    "        v_json_dict = self.get_pipeline_json()\n",
    "        return_dict['response'] = v_json_dict['response']\n",
    "\n",
    "        if v_json_dict['status'] == 'ok':\n",
    "            v_pipeline_spec = v_json_dict['response']['spec']\n",
    "            v_pipeline_spec['name'] = p_name\n",
    "            v_update_response_dict = self.lakeflow_api.update_pipeline(self.pipeline_id, v_pipeline_spec)\n",
    "            return_dict.update(v_update_response_dict)\n",
    "            if v_update_response_dict['status'] == 'ok':\n",
    "                return_dict['message'] = 'Pipeline Name Updated'\n",
    "            else:\n",
    "                return_dict['message'] =  'Pipeline Name Updated Failed'  \n",
    "        else:\n",
    "            return_dict['message'] = f'Pipeline Get Definition Failed: See Response Object'\n",
    "\n",
    "        return return_dict\n",
    "    \n",
    "    def get_gateway_api(self):\n",
    "        return LakeflowGatewayAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca95716-a27a-4a66-8bde-fb0773d627f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# obj = UpdateSqlGatewayPipeline('8e62c559-6817-4330-bab9-109a0b89d194') \n",
    "# #('dba0fd7a-15cc-4eea-906c-fe84667220fc')\n",
    "# print(obj.get_pipeline_json())\n",
    "# # gw_sqlcdc_global_nprod_c2c_shared_sql_server_700084\n",
    "# # # Standard_E4d_v4\n",
    "# # # Standard_DS3_v2\n",
    "# # v_clusters = [{\"label\": \"default\",\"driver_node_type_id\": \"Standard_E4d_v4\",\"node_type_id\": \"Standard_DS3_v2\",\"num_workers\": 1}]\n",
    "# # print(obj.update_pipeline_clusters(v_clusters))\n",
    "# print(obj.update_pipeline_name('gw_sqlcdc_global_nprod_c2c_shared_sql_server_700084'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a657fa78-7811-4eae-8457-358566e79d8b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"SourceServerName1\":304},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762052931503}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lakeflowsql = LakeFlowSqlGateway('dev', 27, 'nprod-c2c-shared-sql-server.database.windows.net')\n",
    "# #lakeflowsql = LakeFlowSqlGateway('dev', 27, 'lewvpalyedb04.nthext.com')\n",
    "# lakeflowsql.process()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GatewayManagementHandler",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
