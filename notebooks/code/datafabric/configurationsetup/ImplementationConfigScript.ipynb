{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18661b3f-bf79-4abf-b314-fe6a1810a29a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_environment_name\", \"\", \"Environment Name\")\n",
    "dbutils.widgets.text(\"p_product_code\", \"\", \"Product Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f3b29b-9472-4828-89cd-c4771cb72136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.sql.functions import col\n",
    "from functools import reduce\n",
    "import uuid, datetime, os, json, re\n",
    "import hashlib, uuid, datetime, os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf656da-5891-48b7-8f33-b16700caa033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../common/DataFabricCommonFunctions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323261b3-9c26-4f1e-a0ab-f9f2b703778b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "v_environment_name =  dbutils.widgets.get(\"p_environment_name\").strip()\n",
    "v_product_code = dbutils.widgets.get(\"p_product_code\").strip()\n",
    "\n",
    "v_locations_dict = get_locations_by_env(v_environment_name)\n",
    "\n",
    "v_file_location = v_locations_dict['source']\n",
    "v_archive_location = v_locations_dict['archive']\n",
    "v_key_Vault_location = v_locations_dict['keyvault']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8a2a83-573d-47f1-8d4e-a04655d8e0ee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Pull db_Configuration"
    }
   },
   "outputs": [],
   "source": [
    "v_df_client_source = execute_dbconfig_sql_query(\"SELECT * from cfg.Client\", v_environment_name)\n",
    "v_df_product_source = execute_dbconfig_sql_query(\"SELECT * from cfg.Product\", v_environment_name)\n",
    "v_df_facility_source = execute_dbconfig_sql_query(\"SELECT * from cfg.Facility\", v_environment_name)\n",
    "v_df_productclient_source = execute_dbconfig_sql_query(\"SELECT * from cfg.ProductClient\", v_environment_name)\n",
    "v_df_productclientfacility_source = execute_dbconfig_sql_query(\"SELECT * from cfg.ProductClientFacility\", v_environment_name)\n",
    "v_df_productinstance_source = execute_dbconfig_sql_query(\"SELECT * from cfg.ProductInstance\", v_environment_name)\n",
    "\n",
    "v_input_internal_product_id = v_df_product_source.filter(col(\"ProductCode\") == f\"{v_product_code}\").first()[\"InternalProductId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0667fcfd-7d97-4315-a766-38d4f847d5e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Setup variables for path and expected schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21275cb9-6231-41a1-98cd-f3bb7e2b7e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "v_attributesystem_df = execute_dbconfig_sql_query(f\"SELECT * from cfg.AttributeSystem where Environment = '{v_environment_name}'\", v_environment_name)\n",
    "v_source_directory = v_file_location + v_attributesystem_df.filter(\"AttributeName = 'AdlsImplementationConfigPath'\").first()[\"AttributeValue\"]\n",
    "v_error_path = v_file_location + v_attributesystem_df.filter(\"AttributeName = 'AdlsImplementationConfigErrorPath'\").first()[\"AttributeValue\"]\n",
    "v_archive_path = v_file_location + v_attributesystem_df.filter(\"AttributeName = 'AdlsImplementationConfigArchivePath'\").first()[\"AttributeValue\"]\n",
    "v_productclient_schema =v_attributesystem_df.filter(\"AttributeName = 'ProductClientSchema'\").first()[\"AttributeValue\"]\n",
    "v_productclientfacility_schema = v_attributesystem_df.filter(\"AttributeName = 'ProductClientFacilitySchema'\").first()[\"AttributeValue\"]\n",
    "v_productinstance_schema = v_attributesystem_df.filter(\"AttributeName = 'ProductInstanceSchema'\").first()[\"AttributeValue\"]\n",
    "v_client_schema = v_attributesystem_df.filter(\"AttributeName = 'ClientSchema'\").first()[\"AttributeValue\"]\n",
    "v_facility_schema = v_attributesystem_df.filter(\"AttributeName = 'FacilitySchema'\").first()[\"AttributeValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f908cd40-5645-472d-b1ec-ae7e2957d490",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read CSVs in the location and load them into dataframes"
    }
   },
   "outputs": [],
   "source": [
    "v_require_exact_order = True\n",
    "\n",
    "def coerce_columns(schema_val):\n",
    "    if isinstance(schema_val, (list, tuple)) and all(isinstance(c, str) for c in schema_val):\n",
    "        return list(schema_val)\n",
    "    if isinstance(schema_val, str):\n",
    "        s = schema_val.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = json.loads(s.replace(\"'\", '\"'))\n",
    "                if isinstance(parsed, list):\n",
    "                    return [str(x) for x in parsed]\n",
    "            except Exception:\n",
    "                pass\n",
    "            inner = s[1:-1]\n",
    "            parts = [p.strip().strip('\"').strip(\"'\") for p in inner.split(\",\")]\n",
    "            return [p for p in parts if p]\n",
    "        parts = [p.strip() for p in s.split(\",\")]\n",
    "        return [p for p in parts if p]\n",
    "    raise ValueError(\"Each v_*_schema must be a list[str] or a string describing columns\")\n",
    "\n",
    "\n",
    "v_schema_cols_map = {\n",
    "    \"client\":                coerce_columns(v_client_schema),\n",
    "    \"facility\":              coerce_columns(v_facility_schema),\n",
    "    \"productclient\":         coerce_columns(v_productclient_schema),\n",
    "    \"productclientfacility\": coerce_columns(v_productclientfacility_schema),\n",
    "    \"productinstance\":       coerce_columns(v_productinstance_schema),\n",
    "}\n",
    "\n",
    "ZERO_WIDTH = \"\".join([\"\\u200B\", \"\\u200C\", \"\\u200D\", \"\\uFEFF\"])\n",
    "ZW_RE = re.compile(f\"[{ZERO_WIDTH}]\")\n",
    " \n",
    "def clean_name(s: str) -> str:\n",
    "    if s is None: return \"\"\n",
    "    s = s.replace(\"\\xa0\", \" \")\n",
    "    s = ZW_RE.sub(\"\", s)\n",
    "    s = s.strip().strip('\"').strip(\"'\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.lower()\n",
    " \n",
    "def normalize_cols(cols): \n",
    "    return [clean_name(c) for c in cols]\n",
    " \n",
    "v_schema_norm_map = {\n",
    "    key: {\n",
    "        \"orig\": cols,\n",
    "        \"seq\":  normalize_cols(cols),\n",
    "        \"set\":  set(normalize_cols(cols))\n",
    "    } for key, cols in v_schema_cols_map.items()\n",
    "}\n",
    " \n",
    "def csv_schema_for(cols):\n",
    "    return T.StructType([T.StructField(c, T.StringType(), True) for c in cols] +\n",
    "                        [T.StructField(\"__corrupt_record\", T.StringType(), True)])\n",
    "\n",
    "CSV_OPTS = {\n",
    "    \"header\": \"true\",\n",
    "    \"inferSchema\": \"false\",\n",
    "    \"encoding\": \"UTF-8\",\n",
    "    \"sep\": \",\",\n",
    "    \"quote\": '\"',\n",
    "    \"escape\": '\"',\n",
    "    \"multiLine\": \"true\",\n",
    "    \"ignoreLeadingWhiteSpace\": \"true\",\n",
    "    \"ignoreTrailingWhiteSpace\": \"true\",\n",
    "    \"mode\": \"PERMISSIVE\",\n",
    "    \"columnNameOfCorruptRecord\": \"__corrupt_record\",\n",
    "}\n",
    "\n",
    "v_files_df = (spark.read.format(\"binaryFile\")\n",
    "            .load(v_source_directory)\n",
    "            .select(\"path\")\n",
    "            .filter(F.lower(F.col(\"path\")).endswith(\".csv\")))\n",
    "v_paths_list = [r[\"path\"] for r in v_files_df.collect()]\n",
    "print(f\"Found {len(v_paths_list)} CSV files in {v_source_directory} (no subfolders)\")\n",
    "\n",
    "v_routing_rows_list = []\n",
    "for p in v_paths_list:\n",
    "    try:\n",
    "        v_head_df = (spark.read.format(\"csv\")\n",
    "                   .options(**{k:v for k,v in CSV_OPTS.items() if k != \"columnNameOfCorruptRecord\"})\n",
    "                   .load(p)\n",
    "                   .limit(1))\n",
    "        v_incoming_cols_list = v_head_df.columns\n",
    "        v_inc_norm_seq_list = normalize_cols(v_incoming_cols_list)\n",
    "        v_inc_norm_set = set(v_inc_norm_seq_list)\n",
    "\n",
    "        v_matched_key = None\n",
    "        for key, info in v_schema_norm_map.items():\n",
    "            if v_require_exact_order:\n",
    "                if v_inc_norm_seq_list == info[\"seq\"]:\n",
    "                    v_matched_key = key; break\n",
    "            else:\n",
    "                if v_inc_norm_set == info[\"set\"]:\n",
    "                    v_matched_key = key; break\n",
    "\n",
    "        v_diff = None\n",
    "        if v_matched_key is None and v_incoming_cols_list:\n",
    "            v_best_key, v_best_overlap = None, -1\n",
    "            for key, info in v_schema_norm_map.items():\n",
    "                overlap = len(v_inc_norm_set & info[\"set\"])\n",
    "                if overlap > v_best_overlap:\n",
    "                    v_best_key, v_best_overlap = key, overlap\n",
    "            if v_best_key:\n",
    "                v_missing_list = list(sorted(info[\"set\"] - v_inc_norm_set))\n",
    "                v_extra_list   = list(sorted(v_inc_norm_set - info[\"set\"]))\n",
    "                v_diff = f\"closest={v_best_key}; missing={v_missing_list}; extra={v_extra_list}\"\n",
    "\n",
    "        v_routing_rows_list.append({\n",
    "            \"path\": p,\n",
    "            \"matched_schema\": v_matched_key,\n",
    "            \"incoming_cols_raw\": \",\".join(v_incoming_cols_list) if v_incoming_cols_list else None,\n",
    "            \"incoming_cols_norm\": \",\".join(v_inc_norm_seq_list) if v_incoming_cols_list else None,\n",
    "            \"debug\": v_diff\n",
    "        })\n",
    "    except Exception as e:\n",
    "        v_routing_rows_list.append({\n",
    "            \"path\": p,\n",
    "            \"matched_schema\": None,\n",
    "            \"incoming_cols_raw\": None,\n",
    "            \"incoming_cols_norm\": None,\n",
    "            \"debug\": f\"header_read_error={str(e)}\"\n",
    "        })\n",
    "\n",
    "v_routing_schema = T.StructType([\n",
    "    T.StructField(\"path\", T.StringType(), True),\n",
    "    T.StructField(\"matched_schema\", T.StringType(), True),\n",
    "    T.StructField(\"incoming_cols_raw\", T.StringType(), True),\n",
    "    T.StructField(\"incoming_cols_norm\", T.StringType(), True),\n",
    "    T.StructField(\"debug\", T.StringType(), True),\n",
    "])\n",
    "v_routing_summary_df = spark.createDataFrame(v_routing_rows_list, v_routing_schema)\n",
    "\n",
    "v_paths_by_schema_dict = { key: [r[\"path\"] for r in v_routing_rows_list if r[\"matched_schema\"] == key] for key in v_schema_cols_map.keys() }\n",
    "v_unmatched_paths_list = [r[\"path\"] for r in v_routing_rows_list if r[\"matched_schema\"] is None and r[\"incoming_cols_norm\"] is not None]\n",
    "v_failed_paths_list    = [r[\"path\"] for r in v_routing_rows_list if r[\"incoming_cols_norm\"] is None]\n",
    "\n",
    "print(\"Matched counts:\", {k: len(v) for k, v in v_paths_by_schema_dict.items()})\n",
    "print(\"Unmatched files (read OK):\", len(v_unmatched_paths_list))\n",
    "print(\"Failed header reads:\", len(v_failed_paths_list))\n",
    "\n",
    "def read_single_with_schema(p, cols):\n",
    "    df = (spark.read.format(\"csv\")\n",
    "            .options(**CSV_OPTS)\n",
    "            .schema(csv_schema_for(cols))\n",
    "            .load(p))\n",
    "    if \"_metadata\" in df.columns:\n",
    "        df = df.select(\"*\", F.col(\"_metadata.file_path\").alias(\"__source_file\"))\n",
    "    else:\n",
    "        df = df.withColumn(\"__source_file\", F.lit(p))\n",
    "    return df.select([F.col(c).cast(\"string\") for c in cols] + [\"__source_file\", \"__corrupt_record\"])\n",
    "\n",
    "def combine_group(paths_list, cols):\n",
    "    if not paths_list:\n",
    "        empty_schema = T.StructType([T.StructField(c, T.StringType(), True) for c in cols] +\n",
    "                                    [T.StructField(\"__source_file\", T.StringType(), True),\n",
    "                                     T.StructField(\"__corrupt_record\", T.StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    dfs = [read_single_with_schema(p, cols) for p in paths_list]\n",
    "    return reduce(lambda a, b: a.unionByName(b, allowMissingColumns=False), dfs)\n",
    "\n",
    "v_client_df                = combine_group(v_paths_by_schema_dict[\"client\"],                v_schema_cols_map[\"client\"])\n",
    "v_facility_df              = combine_group(v_paths_by_schema_dict[\"facility\"],              v_schema_cols_map[\"facility\"])\n",
    "v_productclient_df         = combine_group(v_paths_by_schema_dict[\"productclient\"],         v_schema_cols_map[\"productclient\"])\n",
    "v_productclientfacility_df = combine_group(v_paths_by_schema_dict[\"productclientfacility\"], v_schema_cols_map[\"productclientfacility\"])\n",
    "v_productinstance_df       = combine_group(v_paths_by_schema_dict[\"productinstance\"],       v_schema_cols_map[\"productinstance\"])\n",
    "\n",
    "def show_df(name, df):\n",
    "    cnt = df.count()\n",
    "    print(f\"{name}: {cnt} rows\")\n",
    "    if cnt > 0:\n",
    "        display(df.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03a3fd1b-114c-44e6-8ebf-07c634ea4a15",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Client csv and upsert into config"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if v_client_df.count() > 0:\n",
    "        for row in v_client_df.collect():\n",
    "            v_client_client_code = row[\"ClientCode\"] if row[\"ClientCode\"] is not None else \"\"\n",
    "            v_client_client_name = row[\"ClientName\"] if row[\"ClientName\"] is not None else \"\"\n",
    "            v_client_salesforce_client_id = row[\"SalesforceClientId\"] if row[\"SalesforceClientId\"] is not None else \"\"\n",
    "            v_client_pas = row[\"PAS\"] if row[\"PAS\"] is not None else \"\"\n",
    "            v_client_pas_code = row[\"PASCode\"] if row[\"PASCode\"] is not None else \"\"\n",
    "            v_client_zone = row[\"Zone\"] if row[\"Zone\"] is not None else \"\"\n",
    "            v_client_state = row[\"State\"] if row[\"State\"] is not None else \"\"\n",
    "            v_client_zip = row[\"ZIP\"] if row[\"ZIP\"] is not None else \"\"\n",
    "            v_client_source_client_id = row[\"SourceClientId\"] if row[\"SourceClientId\"] is not None else \"\"\n",
    "            v_client_dwh_server_name = row[\"DWHServerName\"] if row[\"DWHServerName\"] is not None else \"\"\n",
    "            v_client_dwh_database_name = row[\"DwhDatabaseName\"] if row[\"DwhDatabaseName\"] is not None else \"\"\n",
    "            v_client_dwh_database_username = row[\"DwhDatabaseUserName\"] if row[\"DwhDatabaseUserName\"] is not None else \"\"\n",
    "            v_new_internal_client_id = execute_dbconfig_sql_query(\"Select Max(InternalClientId) + 1 As InternalClientId From cfg.Client Where InternalClientId < 700000\", v_environment_name).first()[\"InternalClientId\"]\n",
    "            try:\n",
    "                v_derived_internal_client_id = v_df_client_source.filter(col(\"ClientCode\") == f\"{v_client_client_code}\").first()[\"InternalClientId\"]\n",
    "            except Exception as e:\n",
    "                v_derived_internal_client_id = None\n",
    "\n",
    "            if v_derived_internal_client_id:\n",
    "                print(f\"Updating cfg.Client for ClientCode {v_client_client_code}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateClient @IsClientExistsInDb = 1, @InternalClientId = '{v_derived_internal_client_id}', @SalesforceClientId = '{v_client_salesforce_client_id}', @ClientCode = '{v_client_client_code}', @ClientName = '{v_client_client_name}', @PAS = '{v_client_pas}', @PASCode = '{v_client_pas_code}', @Zone = '{v_client_zone}', @State = '{v_client_state}', @Zip = '{v_client_zip}', @DWHServerName = '{v_client_dwh_server_name}', @DwhDatabaseName = '{v_client_dwh_database_name}', @DwhDataloadUserName = '{v_client_dwh_database_username}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Inserting cfg.Client for ClientCode {v_client_client_code}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateClient @IsClientExistsInDb = 0, @InternalClientId = {v_new_internal_client_id}, @SalesforceClientId = {v_client_salesforce_client_id}, @ClientCode = '{v_client_client_code}', @ClientName = '{v_client_client_name}', @PAS = '{v_client_pas}', @PASCode = '{v_client_pas_code}', @Zone = '{v_client_zone}', @State = '{v_client_state}', @Zip = '{v_client_zip}', @DWHServerName = '{v_client_dwh_server_name}', @DwhDatabaseName = '{v_client_dwh_database_name}', @DwhDataloadUserName = '{v_client_dwh_database_username}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "except Exception as e:\n",
    "    print(f\"Skipping Client. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db912a08-7903-40ec-a8ce-9817ed7adc38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Facility csv and upsert into config"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if v_facility_df.count() > 0:\n",
    "        for row in v_facility_df.collect():\n",
    "            v_facility_client_code = row[\"ClientCode\"] if row[\"ClientCode\"] is not None else \"\"\n",
    "            v_facility_client_name = row[\"ClientName\"] if row[\"ClientName\"] is not None else \"\"\n",
    "            v_facility_facility_code = row[\"FacilityCode\"] if row[\"FacilityCode\"] is not None else \"\"\n",
    "            v_facility_facility_name = row[\"FacilityName\"] if row[\"FacilityName\"] is not None else \"\"\n",
    "            v_facility_facility_type = row[\"FacilityType\"] if row[\"FacilityType\"] is not None else \"\"\n",
    "            v_facility_salesforce_facility_id = row[\"SalesforceFacilityId\"] if row[\"SalesforceFacilityId\"] is not None else \"\"\n",
    "            v_facility_pas = row[\"PAS\"] if row[\"PAS\"] is not None else \"\"\n",
    "            v_facility_pas_code = row[\"PASCode\"] if row[\"PASCode\"] is not None else \"\"\n",
    "            v_facility_pas_category = row[\"PASCategory\"] if row[\"PASCategory\"] is not None else \"\"\n",
    "            v_facility_pas_subcategory = row[\"PASSubCategory\"] if row[\"PASSubCategory\"] is not None else \"\"\n",
    "            v_facility_zone = row[\"Zone\"] if row[\"Zone\"] is not None else \"\"\n",
    "            v_facility_state = row[\"State\"] if row[\"State\"] is not None else \"\"\n",
    "            v_facility_zip = row[\"ZIP\"] if row[\"ZIP\"] is not None else \"\"\n",
    "            v_facility_group_name = row[\"FacilityGroupName\"] if row[\"FacilityGroupName\"] is not None else \"\"\n",
    "            v_derived_internal_client_id = v_df_client_source.filter(col(\"ClientCode\") == f\"{v_facility_client_code}\").first()[\"InternalClientId\"]\n",
    "            try:\n",
    "                v_derived_internal_facility_id = execute_dbconfig_sql_query(f\"Select InternalFacilityId From cfg.Facility Where InternalClientId = {v_derived_internal_client_id} and FacilityName = '{v_facility_facility_name}'\", v_environment_name).first()[\"InternalFacilityId\"]\n",
    "            except Exception as e:\n",
    "                v_derived_internal_facility_id = None\n",
    "            v_new_internal_facility_id = execute_dbconfig_sql_query(\"Select Max(InternalFacilityId) + 1 As InternalFacilityId From cfg.Facility Where InternalFacilityId < 20000\", v_environment_name).first()[\"InternalFacilityId\"]\n",
    "\n",
    "            if v_derived_internal_facility_id:\n",
    "                print(f\"Updating cfg.Facility for FacilityName {v_facility_facility_name}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateFacility @IsFacilityExistsInDb = 1, @InternalClientId = {v_derived_internal_client_id}, @InternalFacilityId = {v_derived_internal_facility_id}, @SalesforceFacilityId = {v_facility_salesforce_facility_id}, @FacilityCode = '{v_facility_facility_code}', @FacilityName = '{v_facility_facility_name}', @FacilityType = '{v_facility_facility_type}', @PAS = '{v_facility_pas}', @PASCode = '{v_facility_pas_code}', @PASCategory = '{v_facility_pas_category}', @PASSubCategory = '{v_facility_pas_subcategory}', @Zone = '{v_facility_zone}', @State = '{v_facility_state}', @Zip = '{v_facility_zip}', @FacilityGroupName = '{v_facility_group_name}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Inserting cfg.Facility for FacilityName {v_facility_facility_name}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateFacility @IsFacilityExistsInDb = 0, @InternalClientId = {v_derived_internal_client_id}, @InternalFacilityId = {v_new_internal_facility_id}, @SalesforceFacilityId = {v_facility_salesforce_facility_id}, @FacilityCode = '{v_facility_facility_code}', @FacilityName = '{v_facility_facility_name}', @FacilityType = '{v_facility_facility_type}', @PAS = '{v_facility_pas}', @PASCode = '{v_facility_pas_code}', @PASCategory = '{v_facility_pas_category}', @PASSubCategory = '{v_facility_pas_subcategory}', @Zone = '{v_facility_zone}', @State = '{v_facility_state}', @Zip = '{v_facility_zip}', @FacilityGroupName = '{v_facility_group_name}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "except Exception as e:\n",
    "    print(f\"Skipping Facility. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68981749-605f-4646-8bc8-d0e029c8e16a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read ProductClient csv and upsert into config"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if v_productclient_df.count() > 0:\n",
    "        for row in v_productclient_df.collect():\n",
    "            v_productclient_client_code = row[\"ClientCode\"] if row[\"ClientCode\"] is not None else \"\"\n",
    "            v_productclient_client_name = row[\"ClientName\"] if row[\"ClientName\"] is not None else \"\"\n",
    "            v_productclient_source_client_id = row[\"SourceClientId\"] if row[\"SourceClientId\"] is not None else \"\"\n",
    "            v_productclient_source_server_name1 = row[\"SourceServerName1\"] if row[\"SourceServerName1\"] is not None else \"\"\n",
    "            v_productclient_source_database_name1 = row[\"SourceDatabaseName1\"] if row[\"SourceDatabaseName1\"] is not None else \"\"\n",
    "            v_productclient_source_server_name2 = row[\"SourceServerName2\"] if row[\"SourceServerName2\"] is not None else \"\"\n",
    "            v_productclient_source_database_name2 = row[\"SourceDatabaseName2\"] if row[\"SourceDatabaseName2\"] is not None else \"\"\n",
    "            v_productclient_source_server_name3 = row[\"SourceServerName3\"] if row[\"SourceServerName3\"] is not None else \"\"\n",
    "            v_productclient_source_database_name3 = row[\"SourceDatabaseName3\"] if row[\"SourceDatabaseName3\"] is not None else \"\"\n",
    "            v_productclient_source_server_name4 = row[\"SourceServerName4\"] if row[\"SourceServerName4\"] is not None else \"\"\n",
    "            v_productclient_source_database_name4 = row[\"SourceDatabaseName4\"] if row[\"SourceDatabaseName4\"] is not None else \"\"\n",
    "            v_productclient_source_server_name5 = row[\"SourceServerName5\"] if row[\"SourceServerName5\"] is not None else \"\"\n",
    "            v_productclient_source_database_name5 = row[\"SourceDatabaseName5\"] if row[\"SourceDatabaseName5\"] is not None else \"\"\n",
    "            v_productclient_process_all_facilities_together = row[\"ProcessAllFacilitiesTogether\"] if row[\"ProcessAllFacilitiesTogether\"] is not None else \"\"\n",
    "            v_productclient_wait_for_all_facilities = row[\"WaitForAllFacilities\"] if row[\"WaitForAllFacilities\"] is not None else \"\"\n",
    "            v_productclient_min_watermark_value = row[\"MinWatermarkValue\"] if row[\"MinWatermarkValue\"] is not None else \"\"\n",
    "            v_productclient_datafactory_name = row[\"DatafactoryName\"] if row[\"DatafactoryName\"] is not None else \"\"\n",
    "            v_productclient_databricks_cluster_id = row[\"DatabricksClusterId\"] if row[\"DatabricksClusterId\"] is not None else \"\"\n",
    "            v_productclient_deployment_group_number = row[\"DeploymentGroupNumber\"] if row[\"DeploymentGroupNumber\"] is not None else \"\"\n",
    "            try:\n",
    "                v_derived_internal_client_id = v_df_client_source.filter(col(\"ClientCode\") == f\"{v_productclient_client_code}\").first()[\"InternalClientId\"]\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"The client code {v_productclient_client_code} does not exist in cfg.Client. Please create a record there first.\")\n",
    "            try:\n",
    "                v_derived_productclient_internal_client_id = v_df_productclient_source.filter(col(\"InternalClientId\") == f\"{v_derived_internal_client_id}\").filter(col(\"InternalProductId\") == f\"{v_input_internal_product_id}\").first()[\"InternalClientId\"]\n",
    "            except Exception as e:\n",
    "                v_derived_productclient_internal_client_id = None\n",
    "\n",
    "            if v_derived_productclient_internal_client_id:\n",
    "                print(f\"Updating cfg.ProductClient for Client {v_derived_productclient_internal_client_id}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateProductClient @IsProductClientExistsInDb = 1, @InternalProductId = '{v_input_internal_product_id}', @InternalClientId = '{v_derived_internal_client_id}', @SourceClientId = '{v_productclient_source_client_id}', @SourceServerName1 = '{v_productclient_source_server_name1}', @SourceDatabaseName1 = '{v_productclient_source_database_name1}', @SourceServerName2 = '{v_productclient_source_server_name2}', @SourceDatabaseName2 = '{v_productclient_source_database_name2}', @SourceServerName3 = '{v_productclient_source_server_name3}', @SourceDatabaseName3 = '{v_productclient_source_database_name3}', @SourceServerName4 = '{v_productclient_source_server_name4}', @SourceDatabaseName4 = '{v_productclient_source_database_name4}', @SourceServerName5 = '{v_productclient_source_server_name5}', @SourceDatabaseName5 = '{v_productclient_source_database_name5}', @ProcessAllFacilitiesTogether = '{v_productclient_process_all_facilities_together}', @WaitForAllFacilities = '{v_productclient_wait_for_all_facilities}', @MinWatermarkValue = '{v_productclient_min_watermark_value}', @DatafactoryName = '{v_productclient_datafactory_name}',  @DatabricksClusterId = '{v_productclient_databricks_cluster_id}', @DeploymentGroupNumber = '{v_productclient_deployment_group_number}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Inserting cfg.ProductClient for Client {v_derived_internal_client_id}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateProductClient @IsProductClientExistsInDb = 0, @InternalProductId = '{v_input_internal_product_id}', @InternalClientId = '{v_derived_internal_client_id}', @SourceClientId = '{v_productclient_source_client_id}', @SourceServerName1 = '{v_productclient_source_server_name1}', @SourceDatabaseName1 = '{v_productclient_source_database_name1}', @SourceServerName2 = '{v_productclient_source_server_name2}', @SourceDatabaseName2 = '{v_productclient_source_database_name2}', @SourceServerName3 = '{v_productclient_source_server_name3}', @SourceDatabaseName3 = '{v_productclient_source_database_name3}', @SourceServerName4 = '{v_productclient_source_server_name4}', @SourceDatabaseName4 = '{v_productclient_source_database_name4}', @SourceServerName5 = '{v_productclient_source_server_name5}', @SourceDatabaseName5 = '{v_productclient_source_database_name5}', @ProcessAllFacilitiesTogether = '{v_productclient_process_all_facilities_together}', @WaitForAllFacilities = '{v_productclient_wait_for_all_facilities}', @MinWatermarkValue = '{v_productclient_min_watermark_value}', @DatafactoryName = '{v_productclient_datafactory_name}', @DatabricksClusterId = '{v_productclient_databricks_cluster_id}', @DeploymentGroupNumber = '{v_productclient_deployment_group_number}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "except Exception as e:\n",
    "    print(f\"Skipping ProductClient. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ceea94b-f7c2-4ca2-95c8-df7c48d5b77b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Iterate over ProductClientFacility data and upsert into config"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if v_productclientfacility_df.count() > 0:\n",
    "        for row in v_productclientfacility_df.collect():\n",
    "            v_productclientfacility_client_code = row[\"ClientCode\"] if row[\"ClientCode\"] is not None else \"\"\n",
    "            v_productclientfacility_client_name = row[\"ClientName\"] if row[\"ClientName\"] is not None else \"\"\n",
    "            v_productclientfacility_facility_code = row[\"FacilityCode\"] if row[\"FacilityCode\"] is not None else \"\"\n",
    "            v_productclientfacility_facility_name = row[\"FacilityName\"] if row[\"FacilityName\"] is not None else \"\"\n",
    "            v_productclientfacility_source_facility_id = row[\"SourceFacilityId\"] if row[\"SourceFacilityId\"] is not None else \"\"\n",
    "            v_productclientfacility_source_facility_code = row[\"SourceFacilityCode\"] if row[\"SourceFacilityId\"] is not None else \"\"\n",
    "            v_productclientfacility_source_server_name1 = row[\"SourceServerName1\"] if row[\"SourceServerName1\"] is not None else \"\"\n",
    "            v_productclientfacility_source_database_name1 = row[\"SourceDatabaseName1\"] if row[\"SourceDatabaseName1\"] is not None else \"\"\n",
    "            v_productclientfacility_source_server_name2 = row[\"SourceServerName2\"] if row[\"SourceServerName2\"] is not None else \"\"\n",
    "            v_productclientfacility_source_database_name2 = row[\"SourceDatabaseName2\"] if row[\"SourceDatabaseName2\"] is not None else \"\"\n",
    "            v_productclientfacility_source_server_name3 = row[\"SourceServerName3\"] if row[\"SourceServerName3\"] is not None else \"\"\n",
    "            v_productclientfacility_source_database_name3 = row[\"SourceDatabaseName3\"] if row[\"SourceDatabaseName3\"] is not None else \"\"\n",
    "            v_productclientfacility_source_server_name4 = row[\"SourceServerName4\"] if row[\"SourceServerName4\"] is not None else \"\"\n",
    "            v_productclientfacility_source_database_name4 = row[\"SourceDatabaseName4\"] if row[\"SourceDatabaseName4\"] is not None else \"\"\n",
    "            v_productclientfacility_project_id = row[\"ProjectId\"] if row[\"ProjectId\"] is not None else \"\"\n",
    "            v_productclientfacility_instance_id = row[\"InstanceId\"] if row[\"InstanceId\"] is not None else \"\"\n",
    "            v_productclientfacility_data_source_id = row[\"DataSourceId\"] if row[\"DataSourceId\"] is not None else \"\"\n",
    "            v_productclientfacility_extract_file_name_pattern = row[\"ExtractFileNamePattern\"] if row[\"ExtractFileNamePattern\"] is not None else \"\"\n",
    "            try:\n",
    "                v_derived_internal_client_id = v_df_client_source.filter(col(\"ClientCode\") == f\"{v_productclientfacility_client_code}\").first()[\"InternalClientId\"]\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"The client code {v_productclientfacility_client_code} doesn't exist in cfg.Client. Please create it there first.\")\n",
    "            try: \n",
    "                v_derived_internal_facility_id = v_df_facility_source.filter(col(\"InternalClientId\") == f\"{v_derived_internal_client_id}\").filter(col(\"FacilityName\") == f\"{v_productclientfacility_facility_name}\").first()[\"InternalFacilityId\"]\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"The facility name {v_productclientfacility_facility_name} doesn't exist in cfg.Client. Please create it there first.\")\n",
    "            v_source_table_count = v_df_productclientfacility_source.filter(col(\"InternalProductId\") == f\"{v_input_internal_product_id}\").filter(col(\"InternalClientId\") == f\"{v_derived_internal_client_id}\").filter(col(\"InternalFacilityId\") == f\"{v_derived_internal_facility_id}\").count()\n",
    "\n",
    "            if v_source_table_count > 1:\n",
    "                print(\"There are more than 1 records of this Client and Facility combination in cfg.ProductClientFacility\")\n",
    "            elif v_source_table_count == 1:\n",
    "                print(f\"Updating cfg.ProductClientFacility for FacilityName {v_productclientfacility_facility_name}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateProductClientFacility @IsProductClientFacilityExistsInDb = 1, @InternalProductId = {v_input_internal_product_id}, @InternalClientId = {v_derived_internal_client_id}, @InternalFacilityId = {v_derived_internal_facility_id}, @SourceFacilityId = '{v_productclientfacility_source_facility_id}', @SourceFacilityCode = '{v_productclientfacility_facility_code}', @SourceServerName1 = '{v_productclientfacility_source_server_name1}', @SourceDatabaseName1 = '{v_productclientfacility_source_database_name1}', @SourceServerName2 = '{v_productclientfacility_source_server_name2}', @SourceDatabaseName2 = '{v_productclientfacility_source_database_name2}', @SourceServerName3 = '{v_productclientfacility_source_server_name3}', @SourceDatabaseName3 = '{v_productclientfacility_source_database_name3}', @SourceServerName4 = '{v_productclientfacility_source_server_name4}', @SourceDatabaseName4 = '{v_productclientfacility_source_database_name4}', @ProjectId = '{v_productclientfacility_project_id}', @InstanceId = '{v_productclientfacility_instance_id}', @DataSourceId = '{v_productclientfacility_data_source_id}', @ExtractFileNamePattern = '{v_productclientfacility_extract_file_name_pattern}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "            else:\n",
    "                if v_derived_internal_client_id and v_derived_internal_facility_id:\n",
    "                    print(f\"Inserting into cfg.ProductClientFacility for FacilityName {v_productclientfacility_facility_name}\")\n",
    "                    execute_dbconfig_stored_procedure(\n",
    "                        f\"\"\"\n",
    "                        EXEC cfg.InsertOrUpdateProductClientFacility @IsProductClientFacilityExistsInDb = 0, @InternalProductId = {v_input_internal_product_id}, @InternalClientId = {v_derived_internal_client_id}, @InternalFacilityId = {v_derived_internal_facility_id}, @SourceFacilityId = '{v_productclientfacility_source_facility_id}', @SourceFacilityCode = '{v_productclientfacility_facility_code}', @SourceServerName1 = '{v_productclientfacility_source_server_name1}', @SourceDatabaseName1 = '{v_productclientfacility_source_database_name1}', @SourceServerName2 = '{v_productclientfacility_source_server_name2}', @SourceDatabaseName2 = '{v_productclientfacility_source_database_name2}', @SourceServerName3 = '{v_productclientfacility_source_server_name3}', @SourceDatabaseName3 = '{v_productclientfacility_source_database_name3}', @SourceServerName4 = '{v_productclientfacility_source_server_name4}', @SourceDatabaseName4 = '{v_productclientfacility_source_database_name4}', @ProjectId = '{v_productclientfacility_project_id}', @InstanceId = '{v_productclientfacility_instance_id}', @DataSourceId = '{v_productclientfacility_data_source_id}', @ExtractFileNamePattern = '{v_productclientfacility_extract_file_name_pattern}'\n",
    "                        \"\"\", v_environment_name\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(\"The provided Client and Facility combinations don't exist in the client or facility source tables.\")\n",
    "except Exception as e:\n",
    "    print(f\"Skipping ProductClientFacility. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f16f5f-61a8-482b-9880-4352fcdae446",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Iterate over ProductInstance data and upsert into config"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if v_productinstance_df.count() > 0:\n",
    "        for row in v_productinstance_df.collect():\n",
    "            v_productinstance_internal_product_id = row[\"InternalProductId\"] if row[\"InternalProductId\"] is not None else \"\"\n",
    "            v_productinstance_data_source_id = row[\"DataSourceId\"] if row[\"DataSourceId\"] is not None else \"\"\n",
    "            v_productinstance_source_server_name1 = row[\"SourceServerName1\"] if row[\"SourceServerName1\"] is not None else \"\"\n",
    "            v_productinstance_source_database_name1 = row[\"SourceDatabaseName1\"] if row[\"SourceDatabaseName1\"] is not None else \"\"\n",
    "            v_productinstance_source_server_name2 = row[\"SourceServerName2\"] if row[\"SourceServerName2\"] is not None else \"\"\n",
    "            v_productinstance_source_database_name2 = row[\"SourceDatabaseName2\"] if row[\"SourceDatabaseName2\"] is not None else \"\"\n",
    "            v_productinstance_source_server_name3 = row[\"SourceServerName3\"] if row[\"SourceServerName3\"] is not None else \"\"\n",
    "            v_productinstance_source_database_name3 = row[\"SourceDatabaseName3\"] if row[\"SourceDatabaseName3\"] is not None else \"\"\n",
    "            v_productinstance_source_server_name4 = row[\"SourceServerName4\"] if row[\"SourceServerName4\"] is not None else \"\"\n",
    "            v_productinstance_source_database_name4 = row[\"SourceDatabaseName4\"] if row[\"SourceDatabaseName4\"] is not None else \"\"\n",
    "            v_productinstance_source_server_name5 = row[\"SourceServerName5\"] if row[\"SourceServerName5\"] is not None else \"\"\n",
    "            v_productinstance_source_database_name5 = row[\"SourceDatabaseName5\"] if row[\"SourceDatabaseName5\"] is not None else \"\"\n",
    "            v_productinstance_min_watermark_value = row[\"MinWatermarkValue\"] if row[\"MinWatermarkValue\"] is not None else \"\"\n",
    "            v_productinstance_datafactory_name = row[\"DatafactoryName\"] if row[\"DatafactoryName\"] is not None else \"\"\n",
    "            v_productinstance_databricks_cluster_name = row[\"DatabricksClusterName\"] if row[\"DatabricksClusterName\"] is not None else \"\"\n",
    "            v_source_table_count = v_df_productinstance_source.filter(col(\"InternalProductId\") == f\"{v_productinstance_internal_product_id}\").filter(col(\"SourceServerName1\") == f\"{v_productinstance_source_server_name1}\").filter(col(\"SourceDatabaseName1\") == f\"{v_productinstance_source_database_name1}\").count()\n",
    "\n",
    "            if v_source_table_count > 1:\n",
    "                print(\"There are more than 1 records of this Product and SourceServerName1 in cfg.ProductInstance\")\n",
    "            elif v_source_table_count == 1:\n",
    "                print(f\"Updating cfg.ProductInstance for this Product {v_productinstance_internal_product_id} and SourceServerName1 {v_productinstance_source_server_name1}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateProductInstance @IsProductInstanceExists = 1, @InternalProductId = {v_input_internal_product_id}, @DataSourceId = {v_productinstance_data_source_id}, @SourceServerName1 = '{v_productinstance_source_server_name1}', @SourceDatabaseName1 = '{v_productinstance_source_database_name1}', @SourceServerName2 = '{v_productinstance_source_server_name2}', @SourceDatabaseName2 = '{v_productinstance_source_database_name2}', @SourceServerName3 = '{v_productinstance_source_server_name3}', @SourceDatabaseName3 = '{v_productinstance_source_database_name3}', @SourceServerName4 = '{v_productinstance_source_server_name4}', @SourceDatabaseName4 = '{v_productinstance_source_database_name4}', @SourceServerName5 = '{v_productinstance_source_server_name5}', @SourceDatabaseName5 = '{v_productinstance_source_database_name5}', @MinWatermarkValue = '{v_productinstance_min_watermark_value}', @DatafactoryName = '{v_productinstance_datafactory_name}', @DatabricksClusterName = '{v_productinstance_databricks_cluster_name}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Inserting cfg.ProductInstance for this Product {v_productinstance_internal_product_id} and SourceServerName1 {v_productinstance_source_server_name1}\")\n",
    "                execute_dbconfig_stored_procedure(\n",
    "                    f\"\"\"\n",
    "                    EXEC cfg.InsertOrUpdateProductInstance @IsProductInstanceExists = 0, @InternalProductId = {v_input_internal_product_id}, @DataSourceId = {v_productinstance_data_source_id}, @SourceServerName1 = '{v_productinstance_source_server_name1}', @SourceDatabaseName1 = '{v_productinstance_source_database_name1}', @SourceServerName2 = '{v_productinstance_source_server_name2}', @SourceDatabaseName2 = '{v_productinstance_source_database_name2}', @SourceServerName3 = '{v_productinstance_source_server_name3}', @SourceDatabaseName3 = '{v_productinstance_source_database_name3}', @SourceServerName4 = '{v_productinstance_source_server_name4}', @SourceDatabaseName4 = '{v_productinstance_source_database_name4}', @SourceServerName5 = '{v_productinstance_source_server_name5}', @SourceDatabaseName5 = '{v_productinstance_source_database_name5}', @MinWatermarkValue = '{v_productinstance_min_watermark_value}', @DatafactoryName = '{v_productinstance_datafactory_name}', @DatabricksClusterName = '{v_productinstance_databricks_cluster_name}'\n",
    "                    \"\"\", v_environment_name\n",
    "                )\n",
    "except Exception as e:\n",
    "    print(f\"Skipping ProductInstance. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb33ad43-7c1d-464f-a241-251add57e7d1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Move the processed CSVs into the Archive or Error directory as necessary"
    }
   },
   "outputs": [],
   "source": [
    "def _basename(p: str) -> str:\n",
    "    return p.split(\"/\")[-1]\n",
    "\n",
    "def _join_path(dir_path: str, filename: str) -> str:\n",
    "    return f\"{dir_path.rstrip('/')}/{filename}\"\n",
    "\n",
    "def _unique_dest(base_dir: str, filename: str) -> str:\n",
    "    ts = datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%S%f\")[:-3]\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    return _join_path(base_dir, f\"{name}__{ts}__{uuid.uuid4().hex[:8]}{ext}\")\n",
    "\n",
    "def _safe_mv(src: str, dest_dir: str):\n",
    "    base = _basename(src)\n",
    "    dest_path = _join_path(dest_dir, base)\n",
    "    if src == dest_path:\n",
    "        return (\"no_op\", dest_path, \"src_equals_dest\")\n",
    "    try:\n",
    "        dbutils.fs.mv(src, dest_path)\n",
    "        return (\"moved\", dest_path, None)\n",
    "    except Exception as e1:\n",
    "        try:\n",
    "            alt_dest = _unique_dest(dest_dir, base)\n",
    "            dbutils.fs.mv(src, alt_dest)\n",
    "            return (\"moved_renamed\", alt_dest, f\"existing_name_or_other: {str(e1)}\")\n",
    "        except Exception as e2:\n",
    "            return (\"failed\", None, f\"{str(e1)} || {str(e2)}\")\n",
    "\n",
    "total_matched = sum(len(v) for v in v_paths_by_schema_dict.values())\n",
    "print(f\"About to move: matched={total_matched}, unmatched={len(v_unmatched_paths_list)}, failed_header_reads={len(v_failed_paths_list)}\")\n",
    "for key, plist in v_paths_by_schema_dict.items():\n",
    "    if plist:\n",
    "        print(f\"  {key}: {len(plist)} files (example: {plist[0]})\")\n",
    "if v_unmatched_paths_list:\n",
    "    print(f\"  unmatched example: {v_unmatched_paths_list[0]}\")\n",
    "if v_failed_paths_list:\n",
    "    print(f\"  failed header read example: {v_failed_paths_list[0]}\")\n",
    "\n",
    "v_move_rows_list = []\n",
    "for key, plist in v_paths_by_schema_dict.items():\n",
    "    for p in plist:\n",
    "        status, dest_path, err = _safe_mv(p, v_archive_path)\n",
    "        v_move_rows_list.append({\"path\": p, \"category\": \"matched\", \"schema_key\": key, \"dest\": dest_path, \"status\": status, \"error\": err})\n",
    "for p in v_unmatched_paths_list:\n",
    "    status, dest_path, err = _safe_mv(p, v_error_path)\n",
    "    v_move_rows_list.append({\"path\": p, \"category\": \"unmatched\", \"schema_key\": None, \"dest\": dest_path, \"status\": status, \"error\": err})\n",
    "for p in v_failed_paths_list:\n",
    "    v_move_rows_list.append({\"path\": p, \"category\": \"read_failed\", \"schema_key\": None, \"dest\": None, \"status\": \"left_in_place\", \"error\": \"header_read_failed\"})\n",
    " \n",
    "v_move_schema = T.StructType([\n",
    "    T.StructField(\"path\", T.StringType(), True),\n",
    "    T.StructField(\"category\", T.StringType(), True),\n",
    "    T.StructField(\"schema_key\", T.StringType(), True),\n",
    "    T.StructField(\"dest\", T.StringType(), True),\n",
    "    T.StructField(\"status\", T.StringType(), True),\n",
    "    T.StructField(\"error\", T.StringType(), True),\n",
    "])\n",
    "v_move_results_df = spark.createDataFrame(v_move_rows_list, v_move_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b125510-2238-41f6-b101-912affc8a29e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit('Execution Complete')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": {
    "autoRunOnWidgetChange": "no-auto-run"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3231370138040799,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ImplementationConfigScript",
   "widgets": {
    "p_environment_name": {
     "currentValue": "",
     "nuid": "363be024-01c2-423d-9c2c-60dfaf5234dd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Environment Name",
      "name": "p_environment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Environment Name",
      "name": "p_environment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "p_product_code": {
     "currentValue": "",
     "nuid": "36a083ae-d41c-4d79-8076-3798c46ccfe7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Product Code",
      "name": "p_product_code",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Product Code",
      "name": "p_product_code",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
