{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53708a17-1b67-466e-900d-267b64764a29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import catalog, jobs, pipelines\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80be26db-0d49-4042-992a-abefd2541bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def switch_pipeline(apiToken, ApiUrl, PipelineID, action=\"stop\", fullRefresh=False, cause=\"Triggered by API\"):\n",
    "    \n",
    "    if action == \"start\":\n",
    "        endpoint = f\"{ApiUrl}/{PipelineID}/updates\"\n",
    "        headers = {\n",
    "        \"Authorization\": f\"Bearer {apiToken}\",\n",
    "        \"Content-Type\": \"application/json\"}\n",
    "        payload = {\n",
    "            \"full_refresh\": fullRefresh,\n",
    "            \"cause\": cause\n",
    "        }\n",
    "    elif action == \"stop\":\n",
    "        headers = {\n",
    "        \"Authorization\": f\"Bearer {apiToken}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        endpoint = f\"{ApiUrl}/{PipelineID}/stop\"\n",
    "        payload = {}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid action. Must be 'start' or 'stop'.\")\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=json.dumps(payload))\n",
    "    print(f\"{action.capitalize()} response status:\", response.status_code)\n",
    "    try:\n",
    "        print(\"Response body:\", response.json())\n",
    "    except Exception as e:\n",
    "        print(\"No JSON response:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c80ee053-2187-4bb5-b38d-10e37602b329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline_status(apiToken, ApiUrl, pipelineID):\n",
    "        #The get_pipeline_status function retrieves the current status of a pipeline, such as IDLE, RUNNING, or STOPPING.\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {apiToken}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    status_url = f\"{ApiUrl}/{pipelineID}\"\n",
    " \n",
    "    response = requests.get(status_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"state\")\n",
    "    elif response.status_code == 404:\n",
    "        return \"NOT_FOUND\"\n",
    "    else:\n",
    "        print(\"Failed to retrieve pipeline status. Status code:\", response.status_code)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ece6410-259a-4fdb-8528-cee8e5bec574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_environment():\n",
    "    try:\n",
    "        value = json.loads(spark.conf.get(\"spark.databricks.clusterUsageTags.clusterAllTags\"))\n",
    "      \n",
    "        tags_dict = {tag[\"key\"]: tag[\"value\"] for tag in value}\n",
    "\n",
    "        environment = tags_dict.get(\"x_Environment\", \"Unknown\")\n",
    " \n",
    "        return environment\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving environment tags: {e}\")\n",
    "        return \"Unknown\", \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c2cf8d1-167e-4147-a483-103957eaa39a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_sub_environment():\n",
    "    try:\n",
    "        value = json.loads(spark.conf.get(\"spark.databricks.clusterUsageTags.clusterAllTags\"))\n",
    "      \n",
    "        tags_dict = {tag[\"key\"]: tag[\"value\"] for tag in value}\n",
    "\n",
    "        sub_environment = tags_dict.get(\"x_SubEnvironment\", \"Unknown\")\n",
    " \n",
    "        return sub_environment\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving environment tags: {e}\")\n",
    "        return  \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f084f30-7a93-4862-acda-333b8d2ed16d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_jdbc_url(environment, subEnvironment, database):\n",
    "    if subEnvironment == 'qa':\n",
    "        subEnvironment = 'qae'\n",
    "    jdbc_hostname = f\"{environment}-analytics-{subEnvironment}-01-sql.database.windows.net\"\n",
    "    jdbc_port = 1433\n",
    "    jdbc_database = f\"{database}\"\n",
    "\n",
    "    # global jdbc_url\n",
    "    jdbc_url = f\"jdbc:sqlserver://{jdbc_hostname}:{jdbc_port};databaseName={jdbc_database};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "    return jdbc_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c7fc0d-4330-43da-a1e0-4114c1a86a84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_connection_properties(username, password):\n",
    "    # global connection_properties\n",
    "    connection_properties = {\n",
    "        \"user\": username,\n",
    "        \"password\": password,\n",
    "        \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "    }\n",
    "    return connection_properties\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "932e1076-69ba-4b8d-ba7c-171bb06d2434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def execute_sql_query(query, jdbc_url, connection_properties):\n",
    "    formatted_query = f\"({query}) as tmp\"\n",
    "    return spark.read.jdbc(url=jdbc_url, table=formatted_query, properties=connection_properties)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DailyIngestionPipelineCommonUtils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
